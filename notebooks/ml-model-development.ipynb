{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28731cb2",
   "metadata": {},
   "source": [
    "Machine Learning Model Development üèóÔ∏èüìä Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d407676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Importa a biblioteca Pandas para manipula√ß√£o de dados\n",
    "import sqlite3  # Importa a biblioteca SQLite para intera√ß√£o com bancos de dados SQLite\n",
    "import numpy as np  # Importa a biblioteca NumPy para opera√ß√µes num√©ricas\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer  # Importa classes para escalonamento de dados\n",
    "from datetime import datetime  # Importa a classe datetime para manipula√ß√£o de datas e hor√°rios\n",
    "from tqdm.auto import tqdm  # Importa a biblioteca tqdm para exibir barras de progresso\n",
    "from sklearn.model_selection import train_test_split # Importa o m√≥dulo Scikit-learn para divis√£o de dados em conjuntos de treino e teste\n",
    "\n",
    "\n",
    "DB_PATH = 'G:/Meu Drive/Documents/GitHubPublished/DataScienceProject/database/ecommerceProject.db'  # Define o caminho para o arquivo do banco de dados SQLite\n",
    "conn = None  # Inicializa a vari√°vel de conex√£o com o banco de dados como None\n",
    "\n",
    "def run_query(query: str, params=()):\n",
    "    \"\"\"\n",
    "    Executa uma consulta SQL no banco de dados e retorna o resultado como um DataFrame.\n",
    "    Adiciona tratamento de erro para a execu√ß√£o da query.\n",
    "\n",
    "    Args:\n",
    "        query (str): A consulta SQL a ser executada.\n",
    "        params (tuple, optional): Par√¢metros para a consulta SQL. Padr√£o √© ().\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: O resultado da consulta como um DataFrame, ou um DataFrame vazio em caso de erro.\n",
    "    \"\"\"\n",
    "    global conn  # Permite que a fun√ß√£o modifique a vari√°vel global conn\n",
    "    if conn is None:  # Verifica se a conex√£o com o banco de dados ainda n√£o foi estabelecida\n",
    "        try:\n",
    "            conn = sqlite3.connect(DB_PATH)  # Conecta ao banco de dados SQLite\n",
    "        except sqlite3.Error as e:  # Captura erros relacionados √† conex√£o com o banco de dados\n",
    "            print(f\"Erro ao conectar ao banco de dados: {e}\")  # Imprime uma mensagem de erro\n",
    "            return pd.DataFrame()  # Retorna um DataFrame vazio em caso de erro\n",
    "\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn, params=params)  # Executa a consulta SQL e armazena os resultados em um DataFrame\n",
    "        return df  # Retorna o DataFrame com os resultados da consulta\n",
    "    except Exception as e:  # Captura outros erros inesperados\n",
    "        print(f\"Erro ao executar a query: {query}\\nErro: {e}\")  # Imprime uma mensagem de erro\n",
    "        return pd.DataFrame()  # Retorna um DataFrame vazio em caso de erro\n",
    "\n",
    "def load_required_data_with_progress():\n",
    "    \"\"\"\n",
    "    Carrega todos os DataFrames necess√°rios para a an√°lise usando consultas SQL com barra de progresso.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicion√°rio onde as chaves s√£o os nomes dos DataFrames e os valores s√£o os DataFrames correspondentes.\n",
    "    \"\"\"\n",
    "    queries = {\n",
    "        'customers': 'SELECT * FROM customers',\n",
    "        'orders': 'SELECT * FROM orders',\n",
    "        'order_items': 'SELECT * FROM order_items',\n",
    "        'products': 'SELECT * FROM products',\n",
    "        'categories': 'SELECT * FROM categories'\n",
    "    }  # Define um dicion√°rio com as consultas SQL para carregar os dados\n",
    "    data = {}  # Inicializa um dicion√°rio para armazenar os DataFrames\n",
    "    print(\"\\n--- Carregando Dados Brutos ---\")  # Imprime uma mensagem indicando que os dados brutos est√£o sendo carregados\n",
    "    for key, query in tqdm(queries.items(), desc=\"Carregando tabelas do DB\"):  # Itera sobre as consultas SQL com barra de progresso\n",
    "        data[key] = run_query(query)  # Executa a consulta e armazena o resultado no dicion√°rio\n",
    "    return data  # Retorna o dicion√°rio com os DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b6289",
   "metadata": {},
   "source": [
    "Machine Learning Model Development üèóÔ∏èüìä Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8c7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Carregando Dados Brutos ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Carregando tabelas do DB: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:22<00:00, 16.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados brutos carregados com sucesso!\n",
      "Clientes: 11161 registros\n",
      "Pedidos: 274794 registros\n",
      "Itens de Pedido: 825534 registros\n",
      "\n",
      "--- Limpeza e Tratamento de Dados ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tratando valores ausentes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.84it/s]\n",
      "Tratando duplicatas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:07<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tratamento Espec√≠fico de Outliers: 'order_value' ---\n",
      "  'order_value': 2748 outliers (acima de 19810.71 ou abaixo de 138.27) foram tratados via Winsoriza√ß√£o.\n"
     ]
    }
   ],
   "source": [
    "# --- Carregar os dados brutos ---\n",
    "raw_data = load_required_data_with_progress()  # Carrega os dados brutos do banco de dados\n",
    "tCustomers = raw_data.get('customers', pd.DataFrame())  # Obt√©m o DataFrame de clientes do dicion√°rio\n",
    "tOrders = raw_data.get('orders', pd.DataFrame())  # Obt√©m o DataFrame de pedidos do dicion√°rio\n",
    "tOrderItens = raw_data.get('order_items', pd.DataFrame())  # Obt√©m o DataFrame de itens de pedido do dicion√°rio\n",
    "tProducts = raw_data.get('products', pd.DataFrame())  # Obt√©m o DataFrame de produtos do dicion√°rio\n",
    "tCategories = raw_data.get('categories', pd.DataFrame())  # Obt√©m o DataFrame de categorias do dicion√°rio\n",
    "\n",
    "if tCustomers.empty or tOrders.empty or tOrderItens.empty:  # Verifica se algum dos DataFrames essenciais n√£o foi carregado\n",
    "    print(\"Erro: Um ou mais DataFrames essenciais n√£o foram carregados. Verifique o caminho do BD ou as queries.\")  # Imprime uma mensagem de erro\n",
    "    exit()  # Encerra o script\n",
    "\n",
    "print(\"Dados brutos carregados com sucesso!\")  # Imprime uma mensagem indicando que os dados brutos foram carregados com sucesso\n",
    "print(f\"Clientes: {len(tCustomers)} registros\")  # Imprime o n√∫mero de registros no DataFrame de clientes\n",
    "print(f\"Pedidos: {len(tOrders)} registros\")  # Imprime o n√∫mero de registros no DataFrame de pedidos\n",
    "print(f\"Itens de Pedido: {len(tOrderItens)} registros\")  # Imprime o n√∫mero de registros no DataFrame de itens de pedido\n",
    "\n",
    "print(\"\\n--- Limpeza e Tratamento de Dados ---\")  # Imprime uma mensagem indicando que a limpeza e tratamento de dados est√£o sendo iniciados\n",
    "\n",
    "tOrders['order_date'] = pd.to_datetime(tOrders['order_date'], errors='coerce')  # Converte a coluna 'order_date' para o tipo datetime\n",
    "\n",
    "for df_name, df in tqdm({\n",
    "    'tCustomers': tCustomers,\n",
    "    'tOrders': tOrders,\n",
    "    'tOrderItens': tOrderItens,\n",
    "    'tProducts': tProducts,\n",
    "    'tCategories': tCategories\n",
    "}.items(), desc=\"Tratando valores ausentes\"):  # Itera sobre os DataFrames com barra de progresso\n",
    "    initial_rows = len(df)  # Armazena o n√∫mero inicial de linhas no DataFrame\n",
    "    for col in df.columns:  # Itera sobre as colunas do DataFrame\n",
    "        if df[col].isnull().any():  # Verifica se a coluna possui valores ausentes\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):  # Verifica se a coluna √© num√©rica\n",
    "                df[col].fillna(df[col].median(), inplace=True)  # Preenche os valores ausentes com a mediana\n",
    "            elif pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):  # Verifica se a coluna √© do tipo string ou objeto\n",
    "                df[col].fillna('Desconhecido', inplace=True)  # Preenche os valores ausentes com a string 'Desconhecido'\n",
    "            else:  # Se a coluna n√£o for num√©rica nem string\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)  # Preenche os valores ausentes com a moda\n",
    "    if len(df) == initial_rows:  # Verifica se o n√∫mero de linhas no DataFrame n√£o foi alterado\n",
    "        pass  # Se o n√∫mero de linhas n√£o foi alterado, n√£o faz nada\n",
    "    else:  # Se o n√∫mero de linhas foi alterado\n",
    "        print(f\"  {df_name}: {initial_rows - len(df)} linhas removidas devido a valores ausentes n√£o trat√°veis.\")  # Imprime uma mensagem indicando que linhas foram removidas\n",
    "\n",
    "for df_name, df, id_col in tqdm([\n",
    "    ('tCustomers', tCustomers, 'customer_id'),\n",
    "    ('tOrders', tOrders, 'order_id'),\n",
    "    ('tOrderItens', tOrderItens, None),\n",
    "    ('tProducts', tProducts, 'product_id'),\n",
    "    ('tCategories', tCategories, 'category_id')\n",
    "], desc=\"Tratando duplicatas\"):  # Itera sobre os DataFrames com barra de progresso\n",
    "    initial_rows = len(df)  # Armazena o n√∫mero inicial de linhas no DataFrame\n",
    "    if id_col and id_col in df.columns:  # Verifica se a coluna de ID foi especificada e existe no DataFrame\n",
    "        df.drop_duplicates(subset=[id_col], inplace=True)  # Remove as linhas duplicadas com base na coluna de ID\n",
    "        if len(df) < initial_rows:  # Verifica se o n√∫mero de linhas no DataFrame foi alterado\n",
    "            print(f\"  {df_name}: {initial_rows - len(df)} duplicatas removidas baseadas em '{id_col}'.\")  # Imprime uma mensagem indicando que linhas foram removidas\n",
    "    else:  # Se a coluna de ID n√£o foi especificada\n",
    "        df.drop_duplicates(inplace=True)  # Remove as linhas duplicadas com base em todas as colunas\n",
    "        if len(df) < initial_rows:  # Verifica se o n√∫mero de linhas no DataFrame foi alterado\n",
    "            print(f\"  {df_name}: {initial_rows - len(df)} duplicatas de linha completa removidas.\")  # Imprime uma mensagem indicando que linhas foram removidas\n",
    "    if len(df) == initial_rows:  # Verifica se o n√∫mero de linhas no DataFrame n√£o foi alterado\n",
    "        pass  # Se o n√∫mero de linhas n√£o foi alterado, n√£o faz nada\n",
    "\n",
    "print(\"\\n--- Tratamento Espec√≠fico de Outliers: 'order_value' ---\")  # Imprime uma mensagem indicando que o tratamento de outliers est√° sendo iniciado\n",
    "if not tOrders.empty and 'order_value' in tOrders.columns:  # Verifica se o DataFrame de pedidos n√£o est√° vazio e se a coluna 'order_value' existe\n",
    "    tOrders['order_value'] = pd.to_numeric(tOrders['order_value'], errors='coerce').fillna(tOrders['order_value'].median())  # Converte a coluna 'order_value' para o tipo num√©rico e preenche os valores ausentes com a mediana\n",
    "\n",
    "    upper_bound_order_value = tOrders['order_value'].quantile(0.995)  # Calcula o limite superior para outliers\n",
    "    lower_bound_order_value = tOrders['order_value'].quantile(0.005)  # Calcula o limite inferior para outliers\n",
    "\n",
    "    initial_outliers = tOrders[(tOrders['order_value'] > upper_bound_order_value) | (tOrders['order_value'] < lower_bound_order_value)].shape[0]  # Calcula o n√∫mero de outliers\n",
    "\n",
    "    tOrders['order_value_cleaned'] = np.where(\n",
    "        tOrders['order_value'] > upper_bound_order_value,\n",
    "        upper_bound_order_value,\n",
    "        np.where(\n",
    "            tOrders['order_value'] < lower_bound_order_value,\n",
    "            lower_bound_order_value,\n",
    "            tOrders['order_value']\n",
    "        )\n",
    "    )  # Aplica a Winsoriza√ß√£o para tratar os outliers\n",
    "    print(f\"  'order_value': {initial_outliers} outliers (acima de {upper_bound_order_value:.2f} ou abaixo de {lower_bound_order_value:.2f}) foram tratados via Winsoriza√ß√£o.\")  # Imprime uma mensagem indicando que os outliers foram tratados\n",
    "else:  # Se o DataFrame de pedidos estiver vazio ou a coluna 'order_value' n√£o existir\n",
    "    print(\"  'order_value' n√£o encontrado ou DataFrame de Pedidos vazio. Nenhum tratamento de outlier realizado.\")  # Imprime uma mensagem indicando que nenhum tratamento de outlier foi realizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbbf6f",
   "metadata": {},
   "source": [
    "Machine Learning Model Development üèóÔ∏èüìä Feature Engineering RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09237da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Engenharia de Atributos: Calculando RFM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\AppData\\Local\\Temp\\ipykernel_4928\\4166753065.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tCustomers['Recency'].fillna(max_recency_val + 30, inplace=True)  # Preenche os valores ausentes de rec√™ncia com um valor alto\n",
      "C:\\Users\\santo\\AppData\\Local\\Temp\\ipykernel_4928\\4166753065.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tCustomers['Frequency'].fillna(0, inplace=True)  # Preenche os valores ausentes de frequ√™ncia com 0\n",
      "C:\\Users\\santo\\AppData\\Local\\Temp\\ipykernel_4928\\4166753065.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tCustomers['Monetary'].fillna(0, inplace=True)  # Preenche os valores ausentes de valor monet√°rio com 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeiras linhas do DataFrame de Clientes com atributos RFM:\n",
      "                            customer_id  Recency  Frequency   Monetary\n",
      "0  80ab0365-8249-48b9-aa62-d3b71868b7a2       21         24  134970.35\n",
      "1  60940726-e1e6-4528-972d-4358ed736124        6         19  137214.48\n",
      "2  c083eb12-9c91-4fcc-8a82-da28f2d8f01f       20         26  138579.58\n",
      "3  21d02d02-2d3d-484f-8d23-a66840eac57b       22         20  125973.50\n",
      "4  0aa2e281-4934-4303-bb70-0e2b1cbf25bf       43         32  208464.15\n",
      "\n",
      "Atributos selecionados para a modelagem: ['Recency', 'Frequency', 'Monetary']\n",
      "\n",
      "--- Escalonando Atributos Num√©ricos ---\n",
      "\n",
      "Primeiras linhas dos atributos RFM escalados:\n",
      "    Recency  Frequency  Monetary\n",
      "0 -0.423855  -0.085414 -0.667908\n",
      "1 -1.258508  -1.140077 -0.601248\n",
      "2 -0.461215   0.304482 -0.560961\n",
      "3 -0.387078  -0.926176 -0.922123\n",
      "4  0.180377   1.435477  1.185430\n",
      "\n",
      "DataFrame final de clientes processados com RFM e RFM escalados:\n",
      "                            customer_id       customer_name  Recency  \\\n",
      "0  80ab0365-8249-48b9-aa62-d3b71868b7a2    Jo√£o Felipe Le√£o       21   \n",
      "1  60940726-e1e6-4528-972d-4358ed736124     Melina da Cunha        6   \n",
      "2  c083eb12-9c91-4fcc-8a82-da28f2d8f01f  Ana Carolina Ramos       20   \n",
      "3  21d02d02-2d3d-484f-8d23-a66840eac57b     Danilo Siqueira       22   \n",
      "4  0aa2e281-4934-4303-bb70-0e2b1cbf25bf        Eloah Foga√ßa       43   \n",
      "\n",
      "   Recency_scaled  Frequency  Frequency_scaled   Monetary  Monetary_scaled  \n",
      "0       -0.423855         24         -0.085414  134970.35        -0.667908  \n",
      "1       -1.258508         19         -1.140077  137214.48        -0.601248  \n",
      "2       -0.461215         26          0.304482  138579.58        -0.560961  \n",
      "3       -0.387078         20         -0.926176  125973.50        -0.922123  \n",
      "4        0.180377         32          1.435477  208464.15         1.185430  \n"
     ]
    }
   ],
   "source": [
    "# --- 1.2. Engenharia de Atributos: Modelo RFM para Previs√£o de Churn ---\n",
    "print(\"\\n--- Engenharia de Atributos: Calculando RFM ---\")  # Imprime uma mensagem indicando que a engenharia de atributos est√° sendo iniciada\n",
    "\n",
    "if not tOrders.empty and 'order_date' in tOrders.columns and tOrders['order_date'].notna().any():  # Verifica se o DataFrame de pedidos n√£o est√° vazio e se a coluna 'order_date' existe\n",
    "    current_date = tOrders['order_date'].max() + pd.Timedelta(days=1)  # Calcula a data atual como a data m√°xima de pedido + 1 dia\n",
    "else:  # Se o DataFrame de pedidos estiver vazio ou a coluna 'order_date' n√£o existir\n",
    "    print(\"  Aviso: 'order_date' n√£o encontrado ou vazio. Usando data atual para Rec√™ncia.\")  # Imprime uma mensagem indicando que a data atual est√° sendo usada\n",
    "    current_date = datetime.now()  # Define a data atual como a data e hora atuais\n",
    "\n",
    "last_purchase = tOrders.groupby('customer_id')['order_date'].max().reset_index()  # Calcula a data da √∫ltima compra para cada cliente\n",
    "last_purchase.columns = ['customer_id', 'LastPurchaseDate']  # Define os nomes das colunas\n",
    "tCustomers = pd.merge(tCustomers, last_purchase, on='customer_id', how='left')  # Mescla os DataFrames de clientes e √∫ltimas compras\n",
    "\n",
    "if 'LastPurchaseDate' in tCustomers.columns:  # Verifica se a coluna 'LastPurchaseDate' existe no DataFrame de clientes\n",
    "    tCustomers['Recency'] = (current_date - tCustomers['LastPurchaseDate']).dt.days  # Calcula a rec√™ncia em dias\n",
    "    max_recency_val = tCustomers['Recency'].max() if not tCustomers['Recency'].empty else 0  # Calcula o valor m√°ximo de rec√™ncia\n",
    "    tCustomers['Recency'].fillna(max_recency_val + 30, inplace=True)  # Preenche os valores ausentes de rec√™ncia com um valor alto\n",
    "else:  # Se a coluna 'LastPurchaseDate' n√£o existir no DataFrame de clientes\n",
    "    tCustomers['Recency'] = max_recency_val + 30  # Define a rec√™ncia como um valor alto\n",
    "\n",
    "order_counts = tOrders.groupby('customer_id')['order_id'].count().reset_index()  # Calcula a frequ√™ncia de compras para cada cliente\n",
    "order_counts.columns = ['customer_id', 'Frequency']  # Define os nomes das colunas\n",
    "tCustomers = pd.merge(tCustomers, order_counts, on='customer_id', how='left')  # Mescla os DataFrames de clientes e contagens de pedidos\n",
    "tCustomers['Frequency'].fillna(0, inplace=True)  # Preenche os valores ausentes de frequ√™ncia com 0\n",
    "\n",
    "monetary_col = 'order_value_cleaned' if 'order_value_cleaned' in tOrders.columns else 'order_value'  # Define a coluna a ser usada para o c√°lculo do valor monet√°rio\n",
    "if monetary_col in tOrders.columns:  # Verifica se a coluna de valor monet√°rio existe no DataFrame de pedidos\n",
    "    total_monetary = tOrders.groupby('customer_id')[monetary_col].sum().reset_index()  # Calcula o valor total gasto por cada cliente\n",
    "    total_monetary.columns = ['customer_id', 'Monetary']  # Define os nomes das colunas\n",
    "    tCustomers = pd.merge(tCustomers, total_monetary, on='customer_id', how='left')  # Mescla os DataFrames de clientes e valores monet√°rios\n",
    "    tCustomers['Monetary'].fillna(0, inplace=True)  # Preenche os valores ausentes de valor monet√°rio com 0\n",
    "else:  # Se a coluna de valor monet√°rio n√£o existir no DataFrame de pedidos\n",
    "    print(f\"  Aviso: Coluna '{monetary_col}' n√£o encontrada para c√°lculo de Valor Monet√°rio. 'Monetary' definido como 0 para todos.\")  # Imprime uma mensagem indicando que a coluna n√£o foi encontrada\n",
    "    tCustomers['Monetary'] = 0  # Define o valor monet√°rio como 0 para todos os clientes\n",
    "\n",
    "print(\"\\nPrimeiras linhas do DataFrame de Clientes com atributos RFM:\")  # Imprime um cabe√ßalho\n",
    "print(tCustomers[['customer_id', 'Recency', 'Frequency', 'Monetary']].head())  # Imprime as primeiras linhas do DataFrame com os atributos RFM\n",
    "\n",
    "features_for_churn = ['Recency', 'Frequency', 'Monetary']  # Define as colunas a serem usadas para modelagem de churn\n",
    "existing_features = [f for f in features_for_churn if f in tCustomers.columns]  # Filtra as colunas que realmente existem no DataFrame\n",
    "\n",
    "if not existing_features:  # Verifica se nenhuma das colunas RFM existe no DataFrame\n",
    "    print(\"\\nErro: Nenhum dos atributos RFM esperados foi encontrado. Verifique a engenharia de atributos.\")  # Imprime uma mensagem de erro\n",
    "    exit()  # Encerra o script\n",
    "\n",
    "X = tCustomers[existing_features].copy()  # Cria uma c√≥pia do DataFrame com as colunas RFM\n",
    "\n",
    "print(f\"\\nAtributos selecionados para a modelagem: {existing_features}\")  # Imprime as colunas selecionadas para a modelagem\n",
    "\n",
    "print(\"\\n--- Escalonando Atributos Num√©ricos ---\")  # Imprime uma mensagem indicando que o escalonamento dos atributos est√° sendo iniciado\n",
    "\n",
    "scaler = QuantileTransformer(output_distribution='normal', random_state=42)  # Cria uma inst√¢ncia do QuantileTransformer\n",
    "\n",
    "if not X.empty:  # Verifica se o DataFrame com os atributos RFM n√£o est√° vazio\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)  # Escala os atributos RFM usando o QuantileTransformer\n",
    "    print(\"\\nPrimeiras linhas dos atributos RFM escalados:\")  # Imprime um cabe√ßalho\n",
    "    print(X_scaled.head())  # Imprime as primeiras linhas dos atributos RFM escalados\n",
    "else:  # Se o DataFrame com os atributos RFM estiver vazio\n",
    "    print(\"  DataFrame de atributos X est√° vazio. Escalonamento n√£o realizado.\")  # Imprime uma mensagem indicando que o escalonamento n√£o foi realizado\n",
    "    X_scaled = pd.DataFrame(columns=existing_features)  # Cria um DataFrame vazio com as colunas RFM\n",
    "\n",
    "base_cols = ['customer_id', 'customer_name']  # Define as colunas base a serem mantidas\n",
    "cols_to_merge = [col for col in base_cols if col in tCustomers.columns]  # Filtra as colunas base que realmente existem no DataFrame\n",
    "tCustomers_processed = tCustomers[cols_to_merge].copy()  # Cria uma c√≥pia do DataFrame com as colunas base\n",
    "\n",
    "for col in existing_features:  # Itera sobre as colunas RFM\n",
    "    tCustomers_processed[col] = X[col]  # Adiciona a coluna RFM ao DataFrame processado\n",
    "    if col in X_scaled.columns:  # Verifica se a coluna RFM escalada existe no DataFrame escalado\n",
    "        tCustomers_processed[f'{col}_scaled'] = X_scaled[col]  # Adiciona a coluna RFM escalada ao DataFrame processado\n",
    "\n",
    "print(\"\\nDataFrame final de clientes processados com RFM e RFM escalados:\")  # Imprime um cabe√ßalho\n",
    "print(tCustomers_processed.head())  # Imprime as primeiras linhas do DataFrame processado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014913b7",
   "metadata": {},
   "source": [
    "Machine Learning Model Development üèóÔ∏èüìä Churn Target Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58a8bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Definindo a Vari√°vel Alvo 'Churn' ---\n",
      "Clientes com Recency > 90 dias s√£o considerados Churn (is_churn = 1).\n",
      "\n",
      "Distribui√ß√£o da vari√°vel 'is_churn':\n",
      "is_churn\n",
      "0    9301\n",
      "1    1860\n",
      "Name: count, dtype: int64\n",
      "Propor√ß√£o de Churn: 0.17\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Definindo a Vari√°vel Alvo 'Churn' ---\")  # Imprime uma mensagem indicando que a defini√ß√£o da vari√°vel alvo est√° sendo iniciada\n",
    "\n",
    "CHURN_THRESHOLD_DAYS = 90  # Define o limiar de rec√™ncia em dias para considerar um cliente como churn\n",
    "\n",
    "tCustomers_processed['is_churn'] = (tCustomers_processed['Recency'] > CHURN_THRESHOLD_DAYS).astype(int)  # Cria a coluna 'is_churn' indicando se o cliente √© churn ou n√£o\n",
    "\n",
    "print(f\"Clientes com Recency > {CHURN_THRESHOLD_DAYS} dias s√£o considerados Churn (is_churn = 1).\")  # Imprime uma mensagem indicando o crit√©rio para definir churn\n",
    "print(\"\\nDistribui√ß√£o da vari√°vel 'is_churn':\")  # Imprime um cabe√ßalho\n",
    "print(tCustomers_processed['is_churn'].value_counts())  # Imprime a distribui√ß√£o da vari√°vel 'is_churn'\n",
    "print(f\"Propor√ß√£o de Churn: {tCustomers_processed['is_churn'].mean():.2f}\")  # Imprime a propor√ß√£o de clientes churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537783a5",
   "metadata": {},
   "source": [
    "Machine Learning Model Development üèóÔ∏èüìä Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa0967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dividindo os Dados em Conjuntos de Treino e Teste ---\n",
      "Tamanho total do dataset: 11161 clientes\n",
      "Tamanho do conjunto de Treino (X_train, y_train): 8928 clientes\n",
      "Tamanho do conjunto de Teste (X_test, y_test): 2233 clientes\n",
      "\n",
      "Propor√ß√£o de Churn no conjunto de Treino:\n",
      "is_churn\n",
      "0    0.833333\n",
      "1    0.166667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Propor√ß√£o de Churn no conjunto de Teste:\n",
      "is_churn\n",
      "0    0.833408\n",
      "1    0.166592\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Dividindo os Dados em Conjuntos de Treino e Teste ---\")  # Imprime uma mensagem indicando que a divis√£o dos dados est√° sendo iniciada\n",
    "\n",
    "X = tCustomers_processed[[f'{col}_scaled' for col in existing_features]].copy()  # Usar as features escaladas\n",
    "y = tCustomers_processed['is_churn'].copy()  # Copia a vari√°vel alvo\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # Importa a fun√ß√£o train_test_split para dividir os dados\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)  # Divide os dados em conjuntos de treino e teste\n",
    "\n",
    "print(f\"Tamanho total do dataset: {len(X)} clientes\")  # Imprime o tamanho total do dataset\n",
    "print(f\"Tamanho do conjunto de Treino (X_train, y_train): {len(X_train)} clientes\")  # Imprime o tamanho do conjunto de treino\n",
    "print(f\"Tamanho do conjunto de Teste (X_test, y_test): {len(X_test)} clientes\")  # Imprime o tamanho do conjunto de teste\n",
    "\n",
    "print(\"\\nPropor√ß√£o de Churn no conjunto de Treino:\")  # Imprime um cabe√ßalho\n",
    "print(y_train.value_counts(normalize=True))  # Imprime a propor√ß√£o de churn no conjunto de treino\n",
    "\n",
    "print(\"\\nPropor√ß√£o de Churn no conjunto de Teste:\")  # Imprime um cabe√ßalho\n",
    "print(y_test.value_counts(normalize=True))  # Imprime a propor√ß√£o de churn no conjunto de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0c59a",
   "metadata": {},
   "source": [
    "Machine Learning Model Development üèóÔ∏èüìä Churn Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bdcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c2ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conex√£o com o banco de dados SQLite fechada.\n"
     ]
    }
   ],
   "source": [
    "if conn:  # Verifica se a conex√£o com o banco de dados foi estabelecida\n",
    "    conn.close()  # Fecha a conex√£o com o banco de dados\n",
    "    print(\"\\nConex√£o com o banco de dados SQLite fechada.\")  # Imprime uma mensagem indicando que a conex√£o foi fechada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
